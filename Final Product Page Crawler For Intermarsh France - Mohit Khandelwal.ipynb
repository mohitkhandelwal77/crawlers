{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\AppData\\Local\\Temp\\ipykernel_19108\\472493040.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = r'chromedriver.exe',chrome_options = chrome_options)\n",
      "C:\\Users\\mohit\\AppData\\Local\\Temp\\ipykernel_19108\\472493040.py:3: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path = r'chromedriver.exe',chrome_options = chrome_options)\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "driver = webdriver.Chrome(executable_path = r'chromedriver.exe',chrome_options = chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputlist = pd.read_excel(r\"carefourinputlist.xlsx\")\n",
    "inputlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputlist.drop_duplicates(inplace=True)\n",
    "inputlist.dropna(inplace = True)\n",
    "asinlist = list(inputlist['Asin '].unique())\n",
    "asinlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Asin','Category','Category Tree','Product URL','Product Title','Product Description','Product Features',\n",
    "                            'Average Rating','Review Count','Ingredients','Product Benefits','Conservation',\n",
    "                           'Operator & Consumer Service','Consumer Benefits','Price','Price Per Quanitity',\n",
    "                           'Quantity','Allergens','Images URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in tqdm(range(0,len(asinlist))):\n",
    "    \n",
    "    i=asinlist[val]\n",
    "    print(i)\n",
    "    carefoururl = \"https://www.carrefour.fr/p/-{}\".format(i)\n",
    "    driver.get(carefoururl)\n",
    "    print(carefoururl)\n",
    "    \n",
    "    \n",
    "    #click all the seemore available \n",
    "    #ingredient\n",
    "    try:\n",
    "        voir_plus_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[4]/div[1]/div/button\")))\n",
    "        voir_plus_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    #productbenefit\n",
    "    try:    \n",
    "        voir_plus_button = WebDriverWait(driver, 1).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[6]/div/div/button\")))\n",
    "        voir_plus_button.click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "    #consumerbenefit\n",
    "    try:\n",
    "        voir_plus_button = WebDriverWait(driver, 1).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[6]/div[2]/div/button\")))\n",
    "        voir_plus_button.click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #refreshing the page\n",
    "    soup=BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    productcomplete=soup.find_all(\"div\",class_=\"pdp__product\")\n",
    "    # Initialize an empty DataFrame to store the extracted data\n",
    "    try:\n",
    "        aa=soup.find_all('li',class_=\"breadcrumb-trail__item\")\n",
    "        categorytree=[x.text.strip() for x in aa[:-1]]\n",
    "        print(categorytree)\n",
    "        \n",
    "    except:\n",
    "        categorytree=\"\"\n",
    "            \n",
    "        \n",
    "    #category\n",
    "    try:\n",
    "        cat1 = soup.find(\"div\",class_=\"regulated-name\")\n",
    "        category=cat1.find(\"p\",class_=\"pl-text pl-text--size-m pl-text--style-p\").text\n",
    "        print(category)\n",
    "    except:\n",
    "        category=\"\"\n",
    "    #Title\n",
    "    try :\n",
    "        prodtitle = soup.find('h1', class_='pl-text--style-subtitle').get_text(strip=True)\n",
    "        print(\"Product Title:\",prodtitle) \n",
    "    except:\n",
    "        prodtitle =\"\"\n",
    "\n",
    "    #description\n",
    "    try:\n",
    "        product_description = soup.find('div', class_='pl-text--style-p').get_text(strip=True)\n",
    "    # Print the product description\n",
    "        print(\"Product Description:\",product_description)\n",
    "    except:\n",
    "        product_description=\"\"\n",
    "        \n",
    "\n",
    "\n",
    "    #nutritional values \n",
    "    try:\n",
    "        nutritional_values_table = soup.find('table', class_='nutritional-details')\n",
    "        nutritional_values_rows = nutritional_values_table.find_all('tr', class_='nutritional-fact')\n",
    "        nutritional_values_dict = {}\n",
    "\n",
    "        for row in nutritional_values_rows:\n",
    "            name = row.find('th', class_='nutritional-fact__name').get_text(strip=True)\n",
    "            value_per_quantity = row.find('td', class_='nutritional-fact__value nutritional-fact__center').get_text(strip=True)\n",
    "            value_percent_element = row.find('td', class_='nutritional-fact__value nutritional-fact__right')\n",
    "            value_percent = value_percent_element.get_text(strip=True) if value_percent_element else None\n",
    "\n",
    "            nutritional_values_dict[name] = {\n",
    "                \"value_per_quantity\": value_per_quantity,\n",
    "                \"value_percent\": value_percent\n",
    "            }\n",
    "\n",
    "        # Print the fetched nutritional details\n",
    "        print(\"Nutritional Values:\")\n",
    "        for name, values in nutritional_values_dict.items():\n",
    "            if values[\"value_percent\"]:\n",
    "                print(f\"{name}: {values['value_per_quantity']} ({values['value_percent']})\")\n",
    "            else:\n",
    "                print(f\"{name}: {values['value_per_quantity']}\")\n",
    "    except:\n",
    "        nutritional_values_dict=\"\"\n",
    "   \n",
    "         #product benefits \n",
    "    try:\n",
    "#         voir_plus_button = WebDriverWait(driver, 5).until(\n",
    "#         EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[6]/div/div/button\")))\n",
    "#         voir_plus_button.click()\n",
    "    \n",
    "#         # Wait for the content to update and parse the updated HTML using BeautifulSoup\n",
    "#         updated_html = driver.page_source\n",
    "#         soup = BeautifulSoup(updated_html, \"html.parser\")\n",
    "\n",
    "        # Find the \"Ingrédients\" section\n",
    "        benefit= soup.find(\"div\", class_=\"product-benefits secondary-details__block\")\n",
    "        productb= benefit.find_all(\"div\",class_=\"product-block-content\")\n",
    "        productbenefit=productb[0].get_text(strip=True)\n",
    "        # Print the \"Ingrédients\" text\n",
    "        print(productbenefit)\n",
    "    except:\n",
    "        productbenefit=\"\"\n",
    " \n",
    "        #consumer benefits\n",
    "    try:\n",
    "#         voir_plus_button = WebDriverWait(driver, 5).until(\n",
    "#         EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[6]/div[2]/div/button\")))\n",
    "#         voir_plus_button.click()\n",
    "\n",
    "#         # Wait for the content to update and parse the updated HTML using BeautifulSoup\n",
    "#         updated_html1 = driver.page_source\n",
    "#         soup1 = BeautifulSoup(updated_html1, \"html.parser\")\n",
    "\n",
    "        # Find the \"Ingrédients\" section\n",
    "        benefit= soup.find(\"div\", class_=\"product-benefits secondary-details__block\")\n",
    "        consumerb= benefit.find_all(\"div\",class_=\"product-block-content\")\n",
    "        consumerbenefit=consumerb[1].get_text(strip=True)\n",
    "        # Print the \"Ingrédients\" text\n",
    "        print(consumerbenefit)\n",
    "    except:\n",
    "        consumerbenefit=\"\"\n",
    "\n",
    "    #product allergens\n",
    "    try:\n",
    "        div_element = soup.find(\"div\", {\"data-testid\": \"product-composition-allergens\", \"class\": \"product-composition-allergens\"})\n",
    "        allergens = div_element.find(\"span\", class_=\"pl-text pl-text--size-m pl-text--style-p\").text\n",
    "        print(\"Allergens:\",allergens)\n",
    "    except:\n",
    "        allergens =\"\"\n",
    "    \n",
    "    #price \n",
    "    finalprice = \"\"  # Initialize the finalprice variable as an empty string\n",
    "\n",
    "    try:\n",
    "        price_element = soup.find(\"div\", {\"data-testid\": \"product-card-price\", \"class\": \"product-card-price\"})\n",
    "        price = price_element.find(\"span\", {\"data-testid\": \"price-displayed\", \"class\": \"pl-text pl-text--size-m pl-text--style-p pl-text--bold product-card-price--final\"}).text\n",
    "        finalprice = price  # If price is available, assign it to finalprice\n",
    "    except AttributeError:  # Handle the AttributeError in case the price is not available\n",
    "        try:\n",
    "            price_element2 = soup.find(\"div\", {\"data-testid\": \"product-card-price\", \"class\": \"product-card-price\"})\n",
    "            discountedprice = price_element2.find(\"span\", {\"data-testid\": \"price-displayed\", \"class\": \"pl-text pl-text--size-m pl-text--style-p pl-text--bold product-card-price--final product-card-price__discount--promo\"}).text\n",
    "            finalprice = discountedprice  # If discounted price is available, assign it to finalprice\n",
    "        except AttributeError:  # Handle the AttributeError in case the discounted price is also not available\n",
    "            try:\n",
    "                price_element3 = soup.find(\"div\", {\"data-testid\": \"product-card-price\", \"class\": \"product-card-price\"})\n",
    "                discountedprice1 = price_element3.find(\"span\", {\"class\": \"pl-text pl-text--size-m pl-text--style-p pl-text--bold product-card-price--final product-card-price__discount--fid\"}).text\n",
    "                finalprice = discountedprice1  # If discounted price is available, assign it to finalprice\n",
    "            except AttributeError:\n",
    "                finalprice = \"\" \n",
    "    print(finalprice)\n",
    "    \n",
    "\n",
    "    #price_per_quantity\n",
    "    try:\n",
    "        price_per = soup.find(\"div\",class_=\"pdp-pricing__group\")\n",
    "        priceperquantity = price_per.find(\"p\",class_=\"pl-text pl-text--size-s pl-text--style-p\").text\n",
    "    \n",
    "    except:\n",
    "        priceperquantity =\"\"\n",
    "    \n",
    "    #quanitity\n",
    "    try:\n",
    "        quantity_element = soup.find(\"div\",class_=\"main-details__header mobile-only\")\n",
    "        quantity = quantity_element.find(\"span\",class_=\"pl-text pl-text--size-m pl-text--style-p pl-text--bold\").text\n",
    "    \n",
    "    except:\n",
    "        quantity =\"\"\n",
    "    \n",
    "    #image data\n",
    "    #first block is for single image\n",
    "    try:\n",
    "        image_element1 = soup.find(\"div\", class_=\"single-image__wrapper\")\n",
    "        zoomable_image_div = image_element1.find(\"div\", class_=\"zoomable-image\")\n",
    "        image_element = zoomable_image_div.find(\"img\", class_=\"zoomable-image__image\")\n",
    "        image_url = image_element[\"data-src\"]\n",
    "        print(image_url)\n",
    "    except: #second block is for multiple image\n",
    "        try:\n",
    "            image_elements = soup.find_all('img', class_=\"image ds-visual-picker__image\")\n",
    "            product_images = [img['src'] for img in image_elements]\n",
    "            product_images1 = [x.replace(\"p_43x43\", \"p_540x540\") for x in product_images]\n",
    "            print(\"Product Images:\")\n",
    "            for image_url in product_images1:\n",
    "                print(image_url)\n",
    "        except:\n",
    "            image_url = \"\"\n",
    "            print(\"Product Image not available.\")\n",
    "\n",
    "    #rating&review Summary\n",
    "    try:\n",
    "         # Find the rating summary element and extract the text\n",
    "        rating_summary_element = soup.find('p', class_='rating-summary__average')\n",
    "        rating_summary = rating_summary_element.get_text(strip=True)\n",
    "\n",
    "        # Find the review count element and extract the text\n",
    "        review_count_element = soup.find('p', class_='rating-summary__count')\n",
    "        review_count = review_count_element.get_text(strip=True)\n",
    "        # Print the rating summary and review count\n",
    "        print(\"Average Rating:\", rating_summary)\n",
    "        print(\"Review Count:\", review_count)\n",
    "    except:\n",
    "        rating_summary=\"\"\n",
    "        review_count=\"\"\n",
    "        \n",
    "    \n",
    "    #Product Features\n",
    "    try:\n",
    "        product_features_heading = soup.find(\"div\",class_=\"product-badge-anchor-heading\").text\n",
    "        content_features = soup.find(\"div\",class_=\"product-badge-anchor-content\").text\n",
    "        # Format and print the output\n",
    "        product_features = f\"{product_features_heading} : {content_features}\"\n",
    "    \n",
    "    except:\n",
    "        product_features = \"\"\n",
    "        \n",
    "   \n",
    "        \n",
    "    #Advice & Consumer Info\n",
    "    try:\n",
    "        advice_consumer_info = soup.find(\"div\",class_=\"product-informations secondary-details__block\")\n",
    "        advice_consumer_info1 = advice_consumer_info.find_all(\"span\",class_=\"pl-text pl-text--size-m pl-text--style-p\")\n",
    "        conservation=advice_consumer_info1[0].text\n",
    "        Operator_contact_Consumer_service=advice_consumer_info1[1].text\n",
    "        \n",
    "    except:\n",
    "        conservation=\"\"\n",
    "        Operator_contact_Consumer_service=\"\"\n",
    "        \n",
    "      \n",
    "    #Ingredient Complete\n",
    "#     try:\n",
    "#         while True:\n",
    "#             voir_plus_button = WebDriverWait(driver,5).until(\n",
    "#             EC.element_to_be_clickable((By.XPATH, \"/html/body/main/div/div/div/div[2]/div/div[1]/div[4]/div[1]/div/button\")))\n",
    "#             voir_plus_button.click()\n",
    "            \n",
    "#     except:\n",
    "#         pass\n",
    "#         # Wait for the content to update and parse the updated HTML using BeautifulSoup\n",
    "#     updated_html = driver.page_source\n",
    "#     soup1 = BeautifulSoup(updated_html, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # Find the \"Ingrédients\" section\n",
    "        ingredient1= soup.find(\"div\", {\"data-testid\": \"product-composition-default-content\", \"class\": \"product-block-content\"})\n",
    "        ingredient= ingredient1.find(\"span\", class_=\"pl-text pl-text--size-m pl-text--style-p\").text\n",
    "        # Print the \"Ingrédients\" text\n",
    "        print(ingredient)\n",
    "    except:\n",
    "        ingredient=\"\"\n",
    "    \n",
    "    # Append the extracted information as a new row to the DataFrame\n",
    "    data = {'Asin':i,'Product URL': carefoururl,'Category': category,'Category Tree': categorytree,\n",
    "            'Nutritional Value':nutritional_values_dict,\n",
    "            'Product Title': prodtitle,\n",
    "            'Product Description': product_description,\n",
    "            'Average Rating': rating_summary,\n",
    "            'Review Count': review_count,\n",
    "            'Ingredients': ingredient,\n",
    "            'Product Features': product_features,\n",
    "            'Product Benefits': productbenefit,\n",
    "            'Consumer Benefits': consumerbenefit,\n",
    "            'Price': finalprice,\n",
    "            'Price Per Quanitity': priceperquantity,\n",
    "            'Quantity': quantity,\n",
    "            'Allergens': allergens,\n",
    "            'Images URL': product_images1,\n",
    "            'Conservation': conservation,'Operator & Consumer Service': Operator_contact_Consumer_service}\n",
    "    df = df.append(data, ignore_index=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the extracted shop details\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'finaloutput_carefour_content_score_ALL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
